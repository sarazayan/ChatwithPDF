# -*- coding: utf-8 -*-
"""GPT4All_Trial_2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Zb49PAJRi-p6zlMe1KooEwJfzoRMoBpf
"""

from google.colab import drive
drive.mount('/content/drive/')

#!ls '/content/drive/MyDrive/Multiple_PDFs'

#!apt-get install poppler-utils  #to present pages of p

!pip install -Uqqq pip --progress-bar off
!pip install -qqq langchain==0.0.173 --progress-bar off
!pip install -qqq chromadb==0.3.23 --progress-bar off
!pip install -qqq pypdf==3.8.1 --progress-bar off
!pip install -qqq pygpt4all==1.1.0 --progress-bar off
!pip install -qqq pdf2image==1.16.3 --progress-bar off

#!gdown 1DpFisoGXsQbpQJvijuvxkLW_pg-FUUMF

#!wget https://gpt4all.io/models/ggml-gpt4all-j-v1.3-groovy.bin #4GB_memory

from langchain.chains import RetrievalQA
from langchain.document_loaders import PyPDFLoader
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.llms import GPT4All
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.vectorstores import Chroma
from pdf2image import convert_from_path
from langchain.retrievers.self_query.base import SelfQueryRetriever

from langchain.document_loaders import PyPDFDirectoryLoader
loader = PyPDFDirectoryLoader('/content/drive/MyDrive/Multiple_PDFs')
docs = loader.load()
type(docs)
print(docs)

#images = convert_from_path("/content/MultiplePDFs/", dpi=88)
#len(images)

#images[0]

#images[1]

#loader = PyPDFLoader("ms-financial-statement.pdf")

documents = loader.load_and_split() #converted into documents for langchain

#documents[0]

#documents[7]

len(documents)

print(documents[0].page_content)

text_splitter = RecursiveCharacterTextSplitter(chunk_size=1024, chunk_overlap=64) #model has only 1000 tokens as limit , it will take both pages and convert it into text
texts = text_splitter.split_documents(documents)

len(texts)

print(texts[0].page_content)
#First page was divided into 2

#Create Embeddings to search for text
embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2") #MiniLM created by microsoft

#to store embeddings in vector database
db = Chroma.from_documents(texts, embeddings, persist_directory="db")
#db.persists 3shan law 3yza t store it in your disk

#to store embeddings in vector database
db = Chroma.from_documents(texts, embeddings, persist_directory="db")
#db.persists 3shan law 3yza t store it in your disk

#Create Chain
#load gpt4all model
model_n_ctx = 1000
model_path = "./ggml-gpt4all-j-v1.3-groovy.bin"
llm = GPT4All(model=model_path, n_ctx=1000, backend="gptj", verbose=False)
#trauned with gpt-j

#Retrieval
#we get source of document
qa = RetrievalQA.from_chain_type(
    llm=llm,
    chain_type="stuff",
    retriever=db.as_retriever(search_kwargs={"k": 3}),
    return_source_documents=True,
    verbose=False,
)
# Page title
st.set_page_config(page_title='Ask your Doc via PaLMðŸŒ´ Model , LangChain ðŸ¦œðŸ”— and Chroma')
st.title('Ask your Doc via PaLMðŸŒ´ Model , LangChain ðŸ¦œðŸ”— and Chroma')

# File upload
uploaded_file = st.file_uploader('Upload text file', type='txt')

# Query text
query_text = st.text_input('Enter your question:', placeholder = 'Please provide a short summary.', disabled=not uploaded_file)
#docs = retriever.get_relevant_documents(qa)

# Commented out IPython magic to ensure Python compatibility.
# #Ask Questions
# %%time
# res = qa(
#     "what is the role of AI in business  ."
# )

res

print(res["result"])

# Commented out IPython magic to ensure Python compatibility.
# %%time
# prompt = f"""How much is the investment amount in Microsoft on 6/22? Extract the answer from the text."""
# res = qa(prompt.strip())

